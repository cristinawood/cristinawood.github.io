---
published: true
layout: post
title: Text Analysis
---
## Text Analysis

This week's readings on text analysis prompted a lot of questions, and answered lots as well. I am reminded once again of the myriad possibilities in the field of digital humanities, and that in exploring disciplinary methods and examining issues from different backgrounds means more potential solutions. As I looked at __How Not to Read a Million Books__, I was reminded again of the crucial  job of correctly and also ***creatively*** characterizing online sources is, in order for potential readers to access them. I wrote:

"I am always wondering how many things I'm missing in a library or archive because of a search algorithm's differences. I say creatively, because so much of the time, a work is categorized with keywords that don't speak to the deeper meaning or themes in the text.
I'm also reminded of a study I heard about which reinforced the need for diversity in a workplace (/everywhere) because of the differences in the ways people from different backgrounds solve problems. On a tech/internet podcast here: https://gimletmedia.com/episode/52-raising-the-bar/. I think this is such a relevant question in archives and libraries - who are the people categorizing texts, and how do they unintentionally favour some sources/themes/keywords/search terms over others?"

In both Tanya Clement's __Text Analysis, Data Mining, and Visualizations in Literary Scholarship__ and  Graham et al.'s __The Historian's Macroscope: Big Digital History__ I was reassured. There is an awareness of the differences in thinking and the human side of interfaces. Clement writes, "the notion that we are constantly met with interfaces (such as the card catalog) that reflect real structures with real people (with all of their quirks and fallibilities and imaginative wonderfulness) in real institutions reminds us how material and constructed (how situated) is the context in which the reader accesses and analyzes cultural content with text analysis, data mining, and visualization methodologies." Topic modelling and interdisciplinary connections offer so many ****possibilities**** as well as challenges!
 
 

Links to this week's readings:

Cottom, Tressie McMillan ‘Nascent Thoughts on Text Analysis Across Disciplines’ http://tressiemc.com/2015/08/06/nascent-thoughts-on-text-analysis-across-disciplines/

Clement, Tanya et al., 2008 “How Not to Read a Million Books”. http://www.people.virginia.edu/~jmu2m/hownot2read.html.

Clement, Tanaya. 2013. “Text Analysis, Data Mining, and Visualizations in Literary Scholarship” https://dlsanthology.mla.hcommons.org/text-analysis-data-mining-and-visualizations-in-literary-scholarship/

Graham, S., I Milligan, S. Weingart The Historian’s Macroscope: Big Digital History http://www.themacroscope.org/?page_id=113

Healy, Kieran. ‘Using Metadata to Find Paul Revere’ https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/

Michel, Jean-Baptiste, et al. 2011 “Quantitative Analysis of Culture Using Millions of Digitized Books,” Science Vol. 331, 176 (14 January 2011). http://www.librarian.net/wp-content/uploads/science-googlelabs.pdf

Moravec, Michelle. ‘Corpus Linguistics for Historians’ http://historyinthecity.blogspot.ca/2013/12/corpus-linguistics-for-historians.html

Rockwell, Geoffrey “What is Text Analysis, Really?,” Literary and Linguistic Computing 18.2 (2003): 209-220. https://doi.org/10.1093/llc/18.2.209

Journal of Cultural Analytics http://culturalanalytics.org/

Schmidt, Ben. 2015 ‘Vector Space Models for the Digital Humanities’ http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html

Speer, Rob. 2017 ‘How to make a racist AI without really trying’ ConceptNet Blog https://blog.conceptnet.io/2017/07/13/how-to-make-a-racist-ai-without-really-trying/

The Syuzhet Episode: http://www.matthewjockers.net/2015/02/02/syuzhet/

https://github.com/mjockers/syuzhet/

https://annieswafford.wordpress.com/2015/03/02/syuzhet/

